# Evaluation

## 评估策略

Video-SME 数据集包含两个任务：**主观性（Subjectivity）任务**和**客观性（Objectivity）任务**，各自评估协议和测试方式不同。

| 任务名称 | 评估形式 | 训练视频 | 测试视频 | 训练 Q&A | 测试协议 | 测试 Q&A |
| -- | -- | -- | -- | -- | -- | -- |
| **1. 主观性任务** | 多分类 | 426 | 72 | 145,107 | P1, P2 | 2,640 (P1), 26,724 (P2) |
| **2. 客观性任务** | 文本生成 | 426 | 72 | 5,762 | -- | 954 |

* **主观性任务**：通过多分类评估，根据视频内容的主观反应指标（SRI）和观众群体信息进行分类评估。P1 协议面向广泛受众，而 P2 协议基于 P1 并结合 SRI 对观众人群特征进行分类。
* **客观性任务**：基于 GPT-3.5 的文本生成评估，借助预训练模型生成对广告内容的客观分析，可参考 [GitHub 项目](https://github.com/mbzuai-oryx/Video-ChatGPT/tree/main/quantitative_evaluation) 进行定量评估。

## 运行推理代码
所有推理均基于OpenAI风格的接口进行，并使用训练后的大模型直接推理获得。

因此，本部分代码不考虑具体模型的推理过程，推荐基于vllm等推理库实现推理，这些引擎库抽象了若干接口细节，降低适配不同模型的难度。

## 评估命令

### 主观性任务
运行以下命令以评估主观性任务：
```sh
sh eval_task1.sh
```

### 客观性任务
运行以下命令以评估客观性任务：
```sh
sh eval_task2.sh
```